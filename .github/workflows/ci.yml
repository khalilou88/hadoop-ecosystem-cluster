name: Hadoop Cluster Test

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:

jobs:
  test-hadoop-cluster:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Docker Compose version
        # Docker Compose V2 is typically pre-installed on GitHub Actions runners.
        # This step ensures it's available and shows the version.
        run: |
          docker compose version

      # - name: Format HDFS NameNode
      #   # This step formats the NameNode before starting the cluster.
      #   # It uses --rm to remove the container immediately after formatting.
      #   run: docker compose run --rm namenode hdfs namenode -format

      - name: Start Hadoop Cluster
        # Start all services in detached mode
        run: docker compose up -d

      - name: Wait for NameNode to be healthy
        # Wait for the NameNode service to report as healthy.
        # This is crucial before interacting with HDFS.
        # We check the health status of the 'namenode' service.
        run: |
          echo "Waiting for NameNode to be healthy..."
          timeout 300s bash -c \
            'until docker compose ps namenode | grep -q "healthy"; do \
              echo -n "."; sleep 5; \
            done' || { echo "NameNode did not become healthy in time!"; exit 1; }
          echo "NameNode is healthy."

      - name: Wait for DataNode to be healthy
        # Wait for the DataNode service to report as healthy.
        run: |
          echo "Waiting for DataNode to be healthy..."
          timeout 300s bash -c \
            'until docker compose ps datanode | grep -q "healthy"; do \
              echo -n "."; sleep 5; \
            done' || { echo "DataNode did not become healthy in time!"; exit 1; }
          echo "DataNode is healthy."

      - name: Wait for ResourceManager to be healthy
        # Wait for the ResourceManager service to report as healthy.
        run: |
          echo "Waiting for ResourceManager to be healthy..."
          timeout 300s bash -c \
            'until docker compose ps resourcemanager | grep -q "healthy"; do \
              echo -n "."; sleep 5; \
            done' || { echo "ResourceManager did not become healthy in time!"; exit 1; }
          echo "ResourceManager is healthy."

      - name: Wait for HistoryServer to be healthy
        # Wait for the MapReduce HistoryServer service to report as healthy.
        run: |
          echo "Waiting for HistoryServer to be healthy..."
          timeout 300s bash -c \
            'until docker compose ps historyserver | grep -q "healthy"; do \
              echo -n "."; sleep 5; \
            done' || { echo "HistoryServer did not become healthy in time!"; exit 1; }
          echo "HistoryServer is healthy."

      - name: Wait for Hive Metastore DB to be healthy
        # Wait for the PostgreSQL database for Hive Metastore to be healthy.
        run: |
          echo "Waiting for Hive Metastore DB to be healthy..."
          timeout 300s bash -c \
            'until docker compose ps hive-metastore-db | grep -q "healthy"; do \
              echo -n "."; sleep 5; \
            done' || { echo "Hive Metastore DB did not become healthy in time!"; exit 1; }
          echo "Hive Metastore DB is healthy."

      - name: Wait for Hive Metastore to be healthy
        # Wait for the Hive Metastore service to report as healthy.
        run: |
          echo "Waiting for Hive Metastore to be healthy..."
          timeout 300s bash -c \
            'until docker compose ps hive-metastore | grep -q "healthy"; do \
              echo -n "."; sleep 5; \
            done' || { echo "Hive Metastore did not become healthy in time!"; exit 1; }
          echo "Hive Metastore is healthy."

      - name: Wait for HiveServer2 to be healthy
        # Wait for the HiveServer2 service to report as healthy.
        run: |
          echo "Waiting for HiveServer2 to be healthy..."
          timeout 300s bash -c \
            'until docker compose ps hiveserver2 | grep -q "healthy"; do \
              echo -n "."; sleep 5; \
            done' || { echo "HiveServer2 did not become healthy in time!"; exit 1; }
          echo "HiveServer2 is healthy."

      - name: Verify HDFS connectivity
        # Execute a simple HDFS command inside the namenode container to verify HDFS is working.
        run: |
          echo "Verifying HDFS connectivity by listing root directory..."
          docker compose exec namenode hdfs dfs -ls /
          echo "HDFS connectivity verified."

      - name: Verify YARN ResourceManager status
        # Execute a simple YARN command to verify ResourceManager is working.
        run: |
          echo "Verifying YARN ResourceManager status..."
          docker compose exec resourcemanager yarn application -list -appStates ALL
          echo "YARN ResourceManager status verified."

      - name: Verify MapReduce framework
        # Test MapReduce functionality by checking if MapReduce framework is properly configured
        run: |
          echo "Verifying MapReduce framework configuration..."
          docker compose exec mapreduce-client mapred version
          echo "MapReduce framework verified."

      - name: Create test directory in HDFS
        # Create a test directory structure for MapReduce job testing
        run: |
          echo "Creating test directories in HDFS..."
          docker compose exec namenode hdfs dfs -mkdir -p /user/test/input
          docker compose exec namenode hdfs dfs -mkdir -p /user/test/output
          echo "Test directories created."

      - name: Create test data for MapReduce
        # Create sample data file for testing MapReduce jobs
        run: |
          echo "Creating test data..."
          docker compose exec mapreduce-client bash -c "echo 'hello world' > /tmp/input.txt"
          docker compose exec mapreduce-client bash -c "echo 'hello hadoop' >> /tmp/input.txt"
          docker compose exec mapreduce-client bash -c "echo 'mapreduce test' >> /tmp/input.txt"
          docker compose exec mapreduce-client hdfs dfs -put /tmp/input.txt /user/test/input/
          echo "Test data uploaded to HDFS."

      - name: Run MapReduce WordCount example
        # Execute the classic WordCount MapReduce example to verify MapReduce functionality
        run: |
          echo "Running MapReduce WordCount example..."
          EXAMPLES_JAR=$(docker compose exec mapreduce-client find /opt/hadoop/share/hadoop/mapreduce -name "hadoop-mapreduce-examples-*.jar" -not -name "*sources*" -not -name "*test*" | head -1 | tr -d '\r')
          echo "Found examples JAR: $EXAMPLES_JAR"
          docker compose exec mapreduce-client hadoop jar \
            "$EXAMPLES_JAR" \
            wordcount /user/test/input /user/test/output/wordcount
          echo "MapReduce WordCount job completed."

      - name: Verify MapReduce job output
        # Check the output of the MapReduce job to ensure it ran successfully
        run: |
          echo "Verifying MapReduce job output..."
          docker compose exec namenode hdfs dfs -cat /user/test/output/wordcount/part-r-00000
          echo "MapReduce job output verified."

      - name: Check job history in HistoryServer
        # Verify that the completed job appears in the MapReduce History Server
        run: |
          echo "Checking job history..."
          # Give the history server a moment to process the completed job
          sleep 10
          docker compose exec historyserver curl -s "http://localhost:19888/ws/v1/history/mapreduce/jobs" | head -100
          echo "Job history check completed."

      - name: Check NameNode UI accessibility
        # Use curl to check if the NameNode UI is responding.
        # -f: Fail silently (no output on HTTP errors).
        # -s: Silent mode (don't show progress meter or error messages).
        # -S: Show error (when -s is used).
        # -o /dev/null: Discard output.
        # -w "%{http_code}": Output HTTP status code.
        run: |
          echo "Checking NameNode UI at http://localhost:9870..."
          until [ "$(curl -s -o /dev/null -w "%{http_code}" http://localhost:9870)" == "302" ]; do
            echo -n "."; sleep 5;
          done
          echo "NameNode UI is accessible."

      - name: Check ResourceManager UI accessibility
        run: |
          echo "Checking ResourceManager UI at http://localhost:8088..."
          until [ "$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8088)" == "302" ]; do
            echo -n "."; sleep 5;
          done
          echo "ResourceManager UI is accessible."

      - name: Check HistoryServer UI accessibility
        # Check if the MapReduce History Server UI is accessible
        run: |
          echo "Checking HistoryServer UI at http://localhost:19888..."
          until [ "$(curl -s -o /dev/null -w "%{http_code}" http://localhost:19888)" == "302" ]; do
            echo -n "."; sleep 5;
          done
          echo "HistoryServer UI is accessible."

      - name: Test MapReduce job submission via YARN
        # Submit another MapReduce job to test YARN integration
        run: |
          echo "Testing MapReduce job submission via YARN..."
          EXAMPLES_JAR=$(docker compose exec mapreduce-client find /opt/hadoop/share/hadoop/mapreduce -name "hadoop-mapreduce-examples-*.jar" -not -name "*sources*" -not -name "*test*" | head -1 | tr -d '\r')
          echo "Found examples JAR: $EXAMPLES_JAR"
          docker compose exec mapreduce-client hadoop jar \
            "$EXAMPLES_JAR" \
            pi 2 10
          echo "MapReduce Pi calculation job completed."

      - name: Verify YARN application history
        # Check that YARN shows the completed applications
        run: |
          echo "Verifying YARN application history..."
          docker compose exec resourcemanager yarn application -list -appStates FINISHED
          echo "YARN application history verified."

      - name: Test Hive Metastore connectivity
        # Test connection to Hive Metastore service by checking if beeline can connect and show databases
        run: |
          echo "Testing Hive Metastore connectivity via beeline..."
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "SHOW DATABASES;" --silent=true --showHeader=false --outputformat=tsv2 | head -5
          echo "Hive Metastore connectivity verified via HiveServer2."

      - name: Create Hive test database
        # Create a test database in Hive using beeline from HiveServer2 container
        run: |
          echo "Creating Hive test database..."
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "CREATE DATABASE IF NOT EXISTS testdb; SHOW DATABASES;" --silent=true
          echo "Hive test database created."

      - name: Create test data in HDFS for Hive
        # Create sample CSV data for Hive table testing with comprehensive logging
        run: |
          echo "============================================"
          echo "Creating test data for Hive tables..."
          echo "Timestamp: $(date)"
          echo "============================================"

          # Function to log with timestamp
          log() {
              echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
          }

          # Function to check command success and continue on error for debugging
          check_status() {
              local exit_code=$?
              if [ $exit_code -eq 0 ]; then
                  log "✅ SUCCESS: $1"
              else
                  log "❌ ERROR: $1 (Exit code: $exit_code)"
              fi
              return $exit_code
          }

          # Step 1: Check container status
          log "Checking container status..."
          docker compose ps
          echo ""

          # Step 2: Check if hiveserver2 container is accessible
          log "Testing hiveserver2 container connectivity..."
          docker compose exec hiveserver2 echo "Container is accessible" 2>&1
          check_status "HiveServer2 container accessibility"
          echo ""

          # Step 3: Check Java processes in containers
          log "Checking Java processes in containers..."

          log "HiveServer2 processes:"
          docker compose exec hiveserver2 jps 2>&1 || log "Cannot get HiveServer2 processes"

          log "Namenode processes:"
          docker compose exec namenode jps 2>&1 || log "Cannot get Namenode processes"

          log "Datanode processes:"
          docker compose exec datanode jps 2>&1 || log "Cannot get Datanode processes"
          echo ""

          # Step 4: Check HDFS filesystem status
          log "Checking HDFS filesystem status..."
          docker compose exec namenode hdfs dfsadmin -report 2>&1
          check_status "HDFS filesystem status"
          echo ""

          # Step 5: Check HDFS safe mode
          log "Checking HDFS safe mode status..."
          SAFE_MODE=$(docker compose exec namenode hdfs dfsadmin -safemode get 2>&1 || echo "ERROR_GETTING_SAFE_MODE")
          log "Safe mode status: $SAFE_MODE"

          if echo "$SAFE_MODE" | grep -q "ON"; then
              log "⚠️  HDFS is in safe mode, attempting to leave..."
              docker compose exec namenode hdfs dfsadmin -safemode leave 2>&1
              check_status "Leaving safe mode"
              sleep 10
              
              # Recheck safe mode
              SAFE_MODE_AFTER=$(docker compose exec namenode hdfs dfsadmin -safemode get 2>&1 || echo "ERROR_GETTING_SAFE_MODE")
              log "Safe mode status after leaving: $SAFE_MODE_AFTER"
          fi
          echo ""

          # Step 6: Check existing HDFS directory structure
          log "Checking existing HDFS directory structure..."

          log "Root directory (/):"
          docker compose exec namenode hdfs dfs -ls / 2>&1 || log "Cannot list root directory"

          log "User directory (/user):"
          docker compose exec namenode hdfs dfs -ls /user 2>&1 || log "/user directory doesn't exist or inaccessible"

          log "Hive directory (/user/hive):"
          docker compose exec namenode hdfs dfs -ls /user/hive 2>&1 || log "/user/hive directory doesn't exist or inaccessible"
          echo ""

          # Step 7: Create base directories using namenode (more reliable)
          log "Creating base HDFS directories using namenode..."

          log "Creating /user directory..."
          docker compose exec namenode hdfs dfs -mkdir -p /user 2>&1
          check_status "Creating /user directory"

          log "Creating /user/hive directory..."
          docker compose exec namenode hdfs dfs -mkdir -p /user/hive 2>&1
          check_status "Creating /user/hive directory"

          log "Creating /user/hive/warehouse directory..."
          docker compose exec namenode hdfs dfs -mkdir -p /user/hive/warehouse 2>&1
          check_status "Creating /user/hive/warehouse directory"

          log "Setting permissions on warehouse directory..."
          docker compose exec namenode hdfs dfs -chmod 777 /user/hive/warehouse 2>&1
          check_status "Setting permissions on warehouse directory"
          echo ""

          # Step 8: Verify directory creation
          log "Verifying directory creation..."
          log "Listing /user/hive contents:"
          docker compose exec namenode hdfs dfs -ls /user/hive 2>&1 || log "Cannot list /user/hive"
          echo ""

          # Step 9: Create CSV file
          log "Creating CSV test file in hiveserver2 container..."
          docker compose exec hiveserver2 bash -c "echo 'id,name,age' > /tmp/employees.csv" 2>&1
          check_status "Creating CSV header"

          docker compose exec hiveserver2 bash -c "echo '1,John,25' >> /tmp/employees.csv" 2>&1
          check_status "Adding first employee record"

          docker compose exec hiveserver2 bash -c "echo '2,Jane,30' >> /tmp/employees.csv" 2>&1
          check_status "Adding second employee record"

          docker compose exec hiveserver2 bash -c "echo '3,Bob,35' >> /tmp/employees.csv" 2>&1
          check_status "Adding third employee record"

          log "Verifying CSV file creation:"
          docker compose exec hiveserver2 cat /tmp/employees.csv 2>&1
          check_status "Verifying CSV file content"
          echo ""

          # Step 10: Test HDFS connectivity from hiveserver2
          log "Testing HDFS connectivity from hiveserver2..."
          log "Listing root directory from hiveserver2:"
          docker compose exec hiveserver2 hdfs dfs -ls / 2>&1
          check_status "HDFS connectivity from hiveserver2"
          echo ""

          # Step 11: Create target directory (try both namenode and hiveserver2)
          log "Creating target directory for employees table..."

          log "Attempting to create directory using namenode..."
          docker compose exec namenode hdfs dfs -mkdir -p /user/hive/warehouse/testdb.db/employees 2>&1
          NAMENODE_RESULT=$?
          check_status "Creating directory via namenode"

          if [ $NAMENODE_RESULT -ne 0 ]; then
              log "Namenode failed, trying with hiveserver2..."
              docker compose exec hiveserver2 hdfs dfs -mkdir -p /user/hive/warehouse/testdb.db/employees 2>&1
              check_status "Creating directory via hiveserver2"
          fi
          echo ""

          # Step 12: Verify directory exists
          log "Verifying target directory exists..."
          docker compose exec namenode hdfs dfs -ls /user/hive/warehouse/testdb.db/ 2>&1
          check_status "Listing testdb.db contents"
          echo ""

          # Step 13: Upload file to HDFS (try multiple approaches)
          log "Uploading CSV file to HDFS..."

          log "Checking HDFS namenode port..."
          docker compose exec namenode netstat -ln | grep :900 || log "Port 9000 info not available"
          docker compose exec namenode netstat -ln | grep :802 || log "Port 8020 info not available"

          log "Approach 1: Upload via hiveserver2 with explicit HDFS URI (port 9000)..."
          docker compose exec hiveserver2 hdfs dfs -put /tmp/employees.csv hdfs://namenode:9000/user/hive/warehouse/testdb.db/employees/ 2>&1
          RESULT_9000=$?

          if [ $RESULT_9000 -ne 0 ]; then
              log "❌ Port 9000 failed, trying port 8020..."
              docker compose exec hiveserver2 hdfs dfs -put /tmp/employees.csv hdfs://namenode:8020/user/hive/warehouse/testdb.db/employees/ 2>&1
              RESULT_8020=$?
              
              if [ $RESULT_8020 -ne 0 ]; then
                  log "❌ Both explicit ports failed, trying default path again..."
                  docker compose exec hiveserver2 hdfs dfs -put /tmp/employees.csv /user/hive/warehouse/testdb.db/employees/ 2>&1
                  RESULT_DEFAULT=$?
                  
                  if [ $RESULT_DEFAULT -ne 0 ]; then
                      log "❌ All hiveserver2 approaches failed, copying to namenode..."
                      # Copy file from hiveserver2 to namenode
                      docker compose exec hiveserver2 cat /tmp/employees.csv | docker compose exec -T namenode bash -c "cat > /tmp/employees.csv"
                      check_status "Copying file to namenode container"
                      
                      # Upload from namenode
                      docker compose exec namenode hdfs dfs -put /tmp/employees.csv /user/hive/warehouse/testdb.db/employees/ 2>&1
                      check_status "Uploading CSV file via namenode"
                  else
                      log "✅ Upload successful with default path on retry"
                  fi
              else
                  log "✅ Upload successful with port 8020"
              fi
          else
              log "✅ Upload successful with port 9000"
          fi
          echo ""

          # Step 14: Verify file upload
          log "Verifying file upload..."
          docker compose exec namenode hdfs dfs -ls /user/hive/warehouse/testdb.db/employees/ 2>&1
          check_status "Listing uploaded files"

          log "Checking file content in HDFS..."
          docker compose exec namenode hdfs dfs -cat /user/hive/warehouse/testdb.db/employees/employees.csv 2>&1
          check_status "Reading uploaded file content"
          echo ""

          # Step 15: Final status
          log "============================================"
          log "Test data creation process completed!"
          log "Timestamp: $(date)"
          log "============================================"

      - name: Create test data in HDFS for Hive
        # Create sample CSV data for Hive table testing using HiveServer2 container
        run: |
          echo "Creating test data for Hive tables..."
          docker compose exec hiveserver2 bash -c "echo 'id,name,age' > /tmp/employees.csv"
          docker compose exec hiveserver2 bash -c "echo '1,John,25' >> /tmp/employees.csv"
          docker compose exec hiveserver2 bash -c "echo '2,Jane,30' >> /tmp/employees.csv"
          docker compose exec hiveserver2 bash -c "echo '3,Bob,35' >> /tmp/employees.csv"
          docker compose exec hiveserver2 hdfs dfs -mkdir -p /user/hive/warehouse/testdb.db/employees
          docker compose exec hiveserver2 hdfs dfs -put /tmp/employees.csv /user/hive/warehouse/testdb.db/employees/
          echo "Test data created and uploaded to HDFS."

      - name: Create Hive external table
        # Create an external Hive table pointing to the test data using beeline from HiveServer2
        run: |
          echo "Creating Hive external table..."
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "USE testdb; 
                CREATE EXTERNAL TABLE IF NOT EXISTS employees (
                  id INT,
                  name STRING,
                  age INT
                ) 
                ROW FORMAT DELIMITED 
                FIELDS TERMINATED BY ',' 
                STORED AS TEXTFILE 
                LOCATION '/user/hive/warehouse/testdb.db/employees'
                TBLPROPERTIES ('skip.header.line.count'='1');" --silent=true
          echo "Hive external table created."

      - name: Test Hive queries
        # Execute various Hive queries to test functionality using beeline from HiveServer2
        run: |
          echo "Testing Hive queries..."
          echo "=== Showing tables ==="
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "USE testdb; SHOW TABLES;" --silent=true

          echo "=== Selecting all records ==="
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "USE testdb; SELECT * FROM employees;" --silent=true

          echo "=== Counting records ==="
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "USE testdb; SELECT COUNT(*) as total_employees FROM employees;" --silent=true

          echo "=== Average age ==="
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "USE testdb; SELECT AVG(age) as avg_age FROM employees;" --silent=true
          echo "Hive queries executed successfully."

      - name: Test Hive with MapReduce integration
        # Test that Hive can execute MapReduce jobs using beeline from HiveServer2
        run: |
          echo "Testing Hive with MapReduce integration..."
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "USE testdb; 
                SET hive.exec.mode.local.auto=false;
                SET mapreduce.job.reduces=1;
                CREATE TABLE IF NOT EXISTS employee_summary AS 
                SELECT 
                  CASE 
                    WHEN age < 30 THEN 'Young' 
                    ELSE 'Senior' 
                  END as age_group,
                  COUNT(*) as count,
                  AVG(age) as avg_age
                FROM employees 
                GROUP BY 
                  CASE 
                    WHEN age < 30 THEN 'Young' 
                    ELSE 'Senior' 
                  END;" --silent=true

          echo "=== Viewing MapReduce results ==="
          docker compose exec hiveserver2 beeline -u "jdbc:hive2://localhost:10000" \
            -e "USE testdb; SELECT * FROM employee_summary;" --silent=true
          echo "Hive MapReduce integration test completed."

      - name: Check HiveServer2 UI accessibility
        # Check if the HiveServer2 Web UI is accessible
        run: |
          echo "Checking HiveServer2 UI at http://localhost:10002..."
          until [ "$(curl -s -o /dev/null -w "%{http_code}" http://localhost:10002)" == "200" ]; do
            echo -n "."; sleep 5;
          done
          echo "HiveServer2 UI is accessible."

      - name: Test Hive CLI functionality
        # Test the traditional Hive CLI (if available) using HiveServer2 container
        run: |
          echo "Testing Hive CLI functionality..."
          docker compose exec hiveserver2 bash -c "echo 'SHOW DATABASES;' | hive --silent" || echo "Hive CLI not available, using Beeline only"
          echo "Hive CLI test completed."

      - name: Verify Hive Metastore schema
        # Verify that the Hive Metastore schema is properly initialized
        run: |
          echo "Verifying Hive Metastore schema..."
          docker compose exec hive-metastore-db psql -U hive -d metastore -c "\dt" | head -10
          echo "Hive Metastore schema verification completed."

      - name: Stop Hadoop Cluster
        # Stop and remove all services, networks, and volumes created by Docker Compose.
        # This ensures a clean state for subsequent runs.
        if: always() # Run this step even if previous steps fail
        run: docker compose down -v
