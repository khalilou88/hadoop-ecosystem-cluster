services:
  namenode:
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    image: apache/hadoop:3
    hostname: namenode
    command: ["hdfs", "namenode"]
    ports:
      - 9870:9870
    env_file:
      - ./config
    environment:
      ENSURE_NAMENODE_DIR: "/tmp/hadoop-root/dfs/name"
    volumes:
      - namenode-data:/tmp/hadoop-root/dfs/name
    networks:
      - hadoop-network
    healthcheck:
      test: ["CMD", "hdfs", "dfsadmin", "-report"]
      interval: 30s
      timeout: 10s
      retries: 5

  datanode:
    image: apache/hadoop:3
    hostname: datanode
    command: ["hdfs", "datanode"]
    env_file:
      - ./config
    volumes:
      - datanode-data:/tmp/hadoop-root/dfs/data
    networks:
      - hadoop-network
    # depends_on:
    #   namenode:
    #     condition: service_healthy
    healthcheck:
      test: ["CMD", "hdfs", "dfsadmin", "-report"]
      interval: 30s
      timeout: 10s
      retries: 5

  resourcemanager:
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    image: apache/hadoop:3
    hostname: resourcemanager
    command: ["yarn", "resourcemanager"]
    ports:
      - 8088:8088
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
    networks:
      - hadoop-network
    # depends_on:
    #   namenode:
    #     condition: service_healthy
    #   datanode:
    #     condition: service_healthy
    healthcheck:
      test: ["CMD", "jps | grep ResourceManager"]
      interval: 30s
      timeout: 10s
      retries: 5

  nodemanager:
    image: apache/hadoop:3
    hostname: nodemanager
    command: ["yarn", "nodemanager"]
    env_file:
      - ./config
    networks:
      - hadoop-network
    # depends_on:
    #   resourcemanager:
    #     condition: service_healthy

  # MapReduce History Server
  historyserver:
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    image: apache/hadoop:3
    hostname: historyserver
    command: ["mapred", "historyserver"]
    ports:
      - 19888:19888
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
    networks:
      - hadoop-network
    # depends_on:
    #   namenode:
    #     condition: service_healthy
    #   resourcemanager:
    #     condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:19888/ws/v1/history/info"]
      interval: 30s
      timeout: 10s
      retries: 5

  # MapReduce Client/Submit Node
  mapreduce-client:
    image: apache/hadoop:3
    hostname: mapreduce-client
    command: ["tail", "-f", "/dev/null"] # Keep container running
    env_file:
      - ./config
    volumes:
      - ./test.sh:/opt/test.sh
      - ./mapreduce-jobs:/opt/mapreduce-jobs # Mount directory for job files
    networks:
      - hadoop-network
    # depends_on:
    #   namenode:
    #     condition: service_healthy
    #   resourcemanager:
    #     condition: service_healthy
    #   historyserver:
    #     condition: service_healthy

networks:
  hadoop-network:
    driver: bridge

volumes:
  namenode-data:
  datanode-data:
